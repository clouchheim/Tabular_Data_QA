{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9797c22a",
   "metadata": {},
   "source": [
    "File to train on the toy_df.csv (that came from the 001_Forbes Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b024a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import TapasConfig, TapasForQuestionAnswering, TapasTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96525ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tokenizer\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "base_tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d0da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the string representation to a list of tuples\n",
    "def parse_answer_coords(coords_str):\n",
    "    try:\n",
    "        # Safely evaluate the string to a Python object\n",
    "        coords = ast.literal_eval(coords_str)\n",
    "        \n",
    "        # Ensure the result is a list of tuples with integers\n",
    "        if isinstance(coords, list) and all(\n",
    "            isinstance(coord, (tuple, list)) and len(coord) == 2 and all(isinstance(x, int) for x in coord)\n",
    "            for coord in coords\n",
    "        ):\n",
    "            return [tuple(coord) for coord in coords]  # Convert lists to tuples if needed\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid format for answer_coords: {coords_str}\")\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        raise ValueError(f\"Error parsing answer_coords: {coords_str}. Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20dcf48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to tokenizer dataset\n",
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = self.process_answer_coords_column(data)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.table_csv_path = 'data/'\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        table = pd.read_csv(self.table_csv_path + item.dataset).astype(\n",
    "            str\n",
    "        )  # be sure to make your table data text only\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            table=table,\n",
    "            queries=item.question,\n",
    "            answer_coordinates=item.answer_coords,\n",
    "            answer_text=item.sample_answer,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # remove the batch dimension which the tokenizer adds by default\n",
    "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        # add the float_answer which is also required (weak supervision for aggregation case)\n",
    "        encoding[\"float_answer\"] = torch.tensor(item.float_answer)\n",
    "        return encoding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # change answer_coords from strings\n",
    "    def process_answer_coords_column(self, data, column_name=\"answer_coords\"):\n",
    "        if column_name not in data.columns:\n",
    "            raise ValueError(f\"Column '{column_name}' does not exist in the dataset.\")\n",
    "\n",
    "        def parse_answer_coords(coords_str):\n",
    "            try:\n",
    "                coords = ast.literal_eval(coords_str)\n",
    "                if isinstance(coords, list) and all(\n",
    "                    isinstance(coord, (tuple, list)) and len(coord) == 2 and all(isinstance(x, int) for x in coord)\n",
    "                    for coord in coords\n",
    "                ):\n",
    "                    return [tuple(coord) for coord in coords]\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid format for answer_coords: {coords_str}\")\n",
    "            except (ValueError, SyntaxError) as e:\n",
    "                raise ValueError(f\"Error parsing answer_coords: {coords_str}. Details: {e}\")\n",
    "        data[column_name] = data[column_name].apply(parse_answer_coords)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afb145ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in toy_df, tokenize and place in dataloader\n",
    "csv_path = 'data/toy_df.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "csv_path_v2 =  'data/toy_df_v2.csv'\n",
    "df_v2 = pd.read_csv(csv_path_v2)\n",
    "\n",
    "datasets = list(set(df['dataset']))\n",
    "train_datasets = datasets[:len(datasets) - 2]\n",
    "dev_datasets = datasets[len(datasets) - 2:]\n",
    "\n",
    "train_df = df[df['dataset'].isin(train_datasets)]\n",
    "train_df_v2 = df_v2[df_v2['dataset'].isin(train_datasets)]\n",
    "dev_df = df[df['dataset'].isin(dev_datasets)]\n",
    "\n",
    "\n",
    "# load train dataloader\n",
    "train_dataset = TableDataset(train_df, tokenizer)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "\n",
    "# load train_v2 dataloader\n",
    "train_dataset_v2 = TableDataset(train_df_v2, tokenizer)\n",
    "train_dataloader_v2 = torch.utils.data.DataLoader(train_dataset_v2, batch_size=8)\n",
    "\n",
    "# load dev dataloader\n",
    "dev_dataset = TableDataset(dev_df, tokenizer)\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=8)\n",
    "\n",
    "# get test datasets\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_dfs = list(set(test_data['dataset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "203843e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in WTQ model (from TAPAS documentation)\n",
    "config = TapasConfig(\n",
    "    num_aggregation_labels=4,\n",
    "    use_answer_as_supervision=True,\n",
    "    answer_loss_cutoff=0.664694,\n",
    "    cell_selection_preference=0.207951,\n",
    "    huber_loss_delta=0.121194,\n",
    "    init_cell_selection_weights_to_zero=True,\n",
    "    select_one_column=True,\n",
    "    allow_empty_column_selection=False,\n",
    "    temperature=0.0352513,\n",
    ")\n",
    "\n",
    "model_wtq = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\", config=config) # leave as is\n",
    "model_finetune = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\", config=config) # finetune\n",
    "optimizer = AdamW(model_finetune.parameters(), lr=1e-5) # trying to change leaening rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43f067f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    train_dataloader, \n",
    "    dev_dataloader, \n",
    "    optimizer, \n",
    "    device, \n",
    "    epochs, \n",
    "    save_path, \n",
    "    description=\"Training Parameters Description\"\n",
    "):\n",
    "    \n",
    "    # Calculate total training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    \n",
    "    # Create scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,  # Optional warm-up period\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    best_dev_loss = float('inf')\n",
    "    model.to(device)\n",
    "    \n",
    "    save_path = 'models/' + save_path\n",
    "    train_losses = [] \n",
    "    dev_losses = []    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        epoch_train_loss /= len(train_dataloader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        \n",
    "        # Evaluate on dev set\n",
    "        epoch_dev_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dev_dataloader, desc=\"Validation\"):\n",
    "                inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "                outputs = model(**inputs)\n",
    "                loss = outputs.loss\n",
    "                epoch_dev_loss += loss.item()\n",
    "        epoch_dev_loss /= len(dev_dataloader)\n",
    "        dev_losses.append(epoch_dev_loss)\n",
    "        \n",
    "        print(f\"Training loss for epoch {epoch + 1}: {epoch_train_loss:.4f}\")\n",
    "        print(f\"Validation loss for epoch {epoch + 1}: {epoch_dev_loss:.4f}\")\n",
    "        \n",
    "    \n",
    "    # Save final model\n",
    "    model.save_pretrained(save_path)\n",
    "    print(f\"fine-tuned model saved to {save_path}\")\n",
    "    \n",
    "    # Plot losses ans save\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(1, epochs + 1), dev_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot with description\n",
    "    plt.savefig(f\"{save_path}/training_loss_plot.png\")\n",
    "    print(f\"Loss plot saved\")\n",
    "    \n",
    "    # Save training description\n",
    "    with open(f\"{save_path}/training_description.txt\", \"w\") as desc_file:\n",
    "        desc_file.write(description)\n",
    "        desc_file.write(f\"\\nEpochs: {epochs}\")\n",
    "        desc_file.write(f\"\\nFinal Train Loss: {train_losses[-1]:.4f}\")\n",
    "        desc_file.write(f\"\\nFinal Validation Loss: {dev_losses[-1]:.4f}\")\n",
    "    \n",
    "    print('Done Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f4b8b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 12/12 [05:32<00:00, 27.75s/it]\n",
      "Validation: 100%|█████████████████████████████████| 2/2 [00:08<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 1: 4.3714\n",
      "Validation loss for epoch 1: 0.4362\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 12/12 [05:08<00:00, 25.74s/it]\n",
      "Validation: 100%|█████████████████████████████████| 2/2 [00:08<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 2: 1.8439\n",
      "Validation loss for epoch 2: 0.2867\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 12/12 [04:51<00:00, 24.28s/it]\n",
      "Validation: 100%|█████████████████████████████████| 2/2 [00:08<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 3: 1.1767\n",
      "Validation loss for epoch 3: 0.2393\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 12/12 [05:21<00:00, 26.79s/it]\n",
      "Validation: 100%|█████████████████████████████████| 2/2 [00:09<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 4: 0.9002\n",
      "Validation loss for epoch 4: 0.2197\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 12/12 [05:18<00:00, 26.54s/it]\n",
      "Validation: 100%|█████████████████████████████████| 2/2 [00:09<00:00,  4.78s/it]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'temperature': 0.0352513}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for epoch 5: 0.8355\n",
      "Validation loss for epoch 5: 0.2134\n",
      "fine-tuned model saved to models/wtq_finetune_five_epoch_lower_learn_schedule\n",
      "Loss plot saved\n",
      "Done Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "description = 'using toy_df.csv, changed learning rate to 1e-5, added a scheduler, only 5 epochs'\n",
    "\n",
    "# Fine-tune model\n",
    "model_finetune = train_model(\n",
    "    model=model_finetune,\n",
    "    train_dataloader=train_dataloader,\n",
    "    dev_dataloader=dev_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    epochs=5,\n",
    "    save_path=\"wtq_finetune_five_epoch_lower_learn_schedule\",\n",
    "    description = description\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11b53811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def inference(test_data, test_dfs, model):\n",
    "    num_none = 0\n",
    "    num_agg = 0\n",
    "    num_correct = 0\n",
    "    num_correct_none = 0\n",
    "    num_correct_agg = 0\n",
    "    total_questions = 0\n",
    "    num_number = 0\n",
    "    num_number_correct = 0\n",
    "    num_category = 0\n",
    "    num_category_correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for file in test_dfs:\n",
    "            print('#################### test on:', file,'####################')\n",
    "            table = pd.read_csv(f'data/{file}').astype(str)\n",
    "            df = test_data[test_data['dataset'] == file]\n",
    "            queries = list(df['question'])\n",
    "            inputs = tokenizer(\n",
    "                table = table,\n",
    "                queries = queries,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "                truncation = True\n",
    "            )\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "                inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n",
    "            )\n",
    "\n",
    "            # print results:\n",
    "            id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n",
    "            aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n",
    "\n",
    "            answers = []\n",
    "            for coordinates in predicted_answer_coordinates:\n",
    "                if len(coordinates) == 1:\n",
    "                    # only a single cell:\n",
    "                    answers.append(table.iat[coordinates[0]])\n",
    "                else:\n",
    "                    # multiple cells\n",
    "                    cell_values = []\n",
    "                    for coordinate in coordinates:\n",
    "                        cell_values.append(table.iat[coordinate])\n",
    "                    answers.append(\", \".join(cell_values))\n",
    "\n",
    "            i = 0\n",
    "            real_answers = list(df['sample_answer'])\n",
    "            answer_type = list(df['type'])\n",
    "            for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n",
    "                total_questions += 1 \n",
    "                #print(query)\n",
    "\n",
    "               # print('Indeded type: ', answer_type[i])\n",
    "                if answer_type[i] == 'number':\n",
    "                    num_number += 1\n",
    "                else:\n",
    "                    num_category += 1\n",
    "\n",
    "                if predicted_agg == \"NONE\":\n",
    "                    #print(\"     Predicted answer: \" + answer)\n",
    "                    #print(\"     Real answer: \", real_answers[i])\n",
    "                    if str(answer) == str(real_answers[i]):\n",
    "                        #print('          CORRECT!')\n",
    "                        num_correct += 1\n",
    "                        num_correct_none += 1\n",
    "                        if answer_type[i] == 'number':\n",
    "                            num_number_correct += 1\n",
    "                        else:\n",
    "                            num_category_correct += 1\n",
    "\n",
    "                    i += 1\n",
    "                    num_none += 1\n",
    "\n",
    "                else:\n",
    "                    #print(\"     Predicted Cells: \" + predicted_agg + \" > \" + answer)\n",
    "                    if predicted_agg == 'COUNT':\n",
    "                        count = answer.split(',')\n",
    "                        answer = len(list(set(count)))\n",
    "                        #print('     Predicted Count: ', answer)\n",
    "                        if answer % 1 == 0:\n",
    "                            answer = int(answer)\n",
    "\n",
    "                    if predicted_agg == 'AVERAGE':\n",
    "                        total = 0\n",
    "                        a = answer.split(',')\n",
    "                        try:\n",
    "                            a = [float(elem) for elem in a]\n",
    "                        except:\n",
    "                            #print('     Predicted Average: Error')\n",
    "                            answer = None\n",
    "                            i += 1\n",
    "                            #print(\"     Real answer: \", str(real_answers[i]))\n",
    "                            num_agg += 1\n",
    "                            continue\n",
    "                        num = len(a)\n",
    "                        answer = 0\n",
    "                        for elem in a:\n",
    "                            answer += (elem/num)  \n",
    "                        #print('     Predicted Average:', answer)\n",
    "                        if answer % 1 == 0:\n",
    "                            answer = int(answer)\n",
    "                            \n",
    "                    if predicted_agg == 'SUM':\n",
    "                        s = answer.split(',')\n",
    "                        s = [float(elem) for elem in s]\n",
    "                        answer = 0\n",
    "                        for elem in s:\n",
    "                            answer += elem\n",
    "                        #print('     Predicted Sum:', answer)\n",
    "                        if answer % 1 == 0:\n",
    "                            answer = int(answer)\n",
    "\n",
    "                    #print(\"     Real answer: \", str(real_answers[i]))\n",
    "                    if str(answer) == str(real_answers[i]):\n",
    "                            #print('          CORRECT!')\n",
    "                            num_correct += 1\n",
    "                            num_correct_agg += 1\n",
    "                            if answer_type[i] == 'number':\n",
    "                                num_number_correct += 1\n",
    "                            else:\n",
    "                                num_category_correct += 1\n",
    "                            \n",
    "                    i += 1\n",
    "                    num_agg += 1\n",
    "\n",
    "        print(\"\")\n",
    "        print('Number of Questions: ', total_questions)\n",
    "        print('Overall Accuracy: ', num_correct/total_questions)\n",
    "        print('Number Accuracy: ', num_number_correct/num_number)\n",
    "        print('Category Accuracy: ', num_category_correct/num_category)\n",
    "        try:\n",
    "            print('NONE Accuracy:', num_correct_none/num_none)\n",
    "        except:\n",
    "            print('***** No questions with predicted Aggregation Tag NONE ***** ')\n",
    "        try:\n",
    "            print('Agg Accuracy:', num_correct_agg/num_agg)\n",
    "        except:\n",
    "            print('***** No questions with predicted Aggregation Tag SUM, AVERAGE, or COUNT ***** ')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89d9ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = TapasForQuestionAnswering.from_pretrained(\"models/wtq_finetune_a\")\n",
    "tok_test = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bf590741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### test on: 037_Ted.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 038_Stroke.csv ####################\n",
      "#################### test on: 036_US.csv ####################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# inference on finetuned model - test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inference(test_data, test_dfs, model_loaded)\n",
      "Cell \u001b[0;32mIn[68], line 22\u001b[0m, in \u001b[0;36minference\u001b[0;34m(test_data, test_dfs, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m df \u001b[38;5;241m=\u001b[39m test_data[test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m file]\n\u001b[1;32m     21\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     23\u001b[0m     table \u001b[38;5;241m=\u001b[39m table,\n\u001b[1;32m     24\u001b[0m     queries \u001b[38;5;241m=\u001b[39m queries,\n\u001b[1;32m     25\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     truncation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     31\u001b[0m predicted_answer_coordinates, predicted_aggregation_indices \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_logits_to_predictions(\n\u001b[1;32m     32\u001b[0m     inputs, outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mdetach(), outputs\u001b[38;5;241m.\u001b[39mlogits_aggregation\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:574\u001b[0m, in \u001b[0;36mTapasTokenizer.__call__\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(queries, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m    575\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m    576\u001b[0m         queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[1;32m    577\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[1;32m    578\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[1;32m    579\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m    580\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    581\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m    582\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m    583\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    584\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[1;32m    585\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m    586\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m    587\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m    588\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m    589\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m    590\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[1;32m    591\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m    596\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m    597\u001b[0m         query\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    614\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:692\u001b[0m, in \u001b[0;36mTapasTokenizer.batch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    687\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    690\u001b[0m     )\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[1;32m    693\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m    694\u001b[0m     queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[1;32m    695\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[1;32m    696\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[1;32m    697\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m    698\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    699\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m    700\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m    701\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    702\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[1;32m    703\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m    704\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m    705\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m    706\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m    707\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[1;32m    708\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[1;32m    709\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    711\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:759\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m     queries[idx] \u001b[38;5;241m=\u001b[39m query\n\u001b[1;32m    757\u001b[0m     queries_tokens\u001b[38;5;241m.\u001b[39mappend(query_tokens)\n\u001b[0;32m--> 759\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_prepare_for_model(\n\u001b[1;32m    760\u001b[0m     table,\n\u001b[1;32m    761\u001b[0m     queries,\n\u001b[1;32m    762\u001b[0m     tokenized_table\u001b[38;5;241m=\u001b[39mtable_tokens,\n\u001b[1;32m    763\u001b[0m     queries_tokens\u001b[38;5;241m=\u001b[39mqueries_tokens,\n\u001b[1;32m    764\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[1;32m    765\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    766\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m    767\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[1;32m    768\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m    769\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m    770\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    771\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[1;32m    772\u001b[0m     prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    773\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[1;32m    774\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m    775\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[1;32m    776\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m    777\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[1;32m    778\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    779\u001b[0m )\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(batch_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:814\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_prepare_for_model\u001b[0;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(raw_queries, queries_tokens, answer_coordinates, answer_text)):\n\u001b[1;32m    813\u001b[0m     raw_query, query_tokens, answer_coords, answer_txt \u001b[38;5;241m=\u001b[39m example\n\u001b[0;32m--> 814\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_for_model(\n\u001b[1;32m    815\u001b[0m         raw_table,\n\u001b[1;32m    816\u001b[0m         raw_query,\n\u001b[1;32m    817\u001b[0m         tokenized_table\u001b[38;5;241m=\u001b[39mtokenized_table,\n\u001b[1;32m    818\u001b[0m         query_tokens\u001b[38;5;241m=\u001b[39mquery_tokens,\n\u001b[1;32m    819\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coords,\n\u001b[1;32m    820\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_txt,\n\u001b[1;32m    821\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m    822\u001b[0m         padding\u001b[38;5;241m=\u001b[39mPaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\u001b[38;5;241m.\u001b[39mvalue,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[1;32m    823\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m    824\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[1;32m    825\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[1;32m    827\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[1;32m    828\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[1;32m    829\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[1;32m    830\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# We convert the whole batch to tensors at the end\u001b[39;00m\n\u001b[1;32m    831\u001b[0m         prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    832\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    833\u001b[0m         prev_answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    834\u001b[0m         prev_answer_text\u001b[38;5;241m=\u001b[39manswer_text[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch_outputs:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1153\u001b[0m, in \u001b[0;36mTapasTokenizer.prepare_for_model\u001b[0;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     prev_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_answer_ids(\n\u001b[1;32m   1148\u001b[0m         column_ids, row_ids, table_data, prev_answer_text, prev_answer_coordinates\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;66;03m# FIRST: parse both the table and question in terms of numeric values\u001b[39;00m\n\u001b[0;32m-> 1153\u001b[0m raw_table \u001b[38;5;241m=\u001b[39m add_numeric_table_values(raw_table)\n\u001b[1;32m   1154\u001b[0m raw_query \u001b[38;5;241m=\u001b[39m add_numeric_values_to_question(raw_query)\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# SECOND: add numeric-related features (and not parse them in these functions):\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2755\u001b[0m, in \u001b[0;36madd_numeric_table_values\u001b[0;34m(table, min_consolidation_fraction, debug_info)\u001b[0m\n\u001b[1;32m   2752\u001b[0m \u001b[38;5;66;03m# Third, add numeric_value attributes to these Cell objects\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_index, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(table\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m   2754\u001b[0m     column_values \u001b[38;5;241m=\u001b[39m _consolidate_numeric_values(\n\u001b[0;32m-> 2755\u001b[0m         _get_column_values(table, col_index),\n\u001b[1;32m   2756\u001b[0m         min_consolidation_fraction\u001b[38;5;241m=\u001b[39mmin_consolidation_fraction,\n\u001b[1;32m   2757\u001b[0m         debug_info\u001b[38;5;241m=\u001b[39m(debug_info, column),\n\u001b[1;32m   2758\u001b[0m     )\n\u001b[1;32m   2760\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row_index, numeric_value \u001b[38;5;129;01min\u001b[39;00m column_values\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2761\u001b[0m         table\u001b[38;5;241m.\u001b[39miloc[row_index, col_index]\u001b[38;5;241m.\u001b[39mnumeric_value \u001b[38;5;241m=\u001b[39m numeric_value\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2672\u001b[0m, in \u001b[0;36m_get_column_values\u001b[0;34m(table, col_index)\u001b[0m\n\u001b[1;32m   2663\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2664\u001b[0m \u001b[38;5;124;03mParses text in column and returns a dict mapping row_index to values. This is the _get_column_values function from\u001b[39;00m\n\u001b[1;32m   2665\u001b[0m \u001b[38;5;124;03mnumber_annotation_utils.py of the original implementation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[38;5;124;03m  col_index: integer, indicating the index of the column to get the numeric values of\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2671\u001b[0m index_to_values \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 2672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_index, row \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m   2673\u001b[0m     text \u001b[38;5;241m=\u001b[39m normalize_for_match(row[col_index]\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m   2674\u001b[0m     index_to_values[row_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(_get_numeric_values(text))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/pandas/core/frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m klass(v, index\u001b[38;5;241m=\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mk)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/pandas/core/generic.py:6262\u001b[0m, in \u001b[0;36mNDFrame.__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   6255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[1;32m   6256\u001b[0m     \u001b[38;5;66;03m# We want attrs propagation to have minimal performance\u001b[39;00m\n\u001b[1;32m   6257\u001b[0m     \u001b[38;5;66;03m# impact if attrs are not used; i.e. attrs is an empty dict.\u001b[39;00m\n\u001b[1;32m   6258\u001b[0m     \u001b[38;5;66;03m# One could make the deepcopy unconditionally, but a deepcopy\u001b[39;00m\n\u001b[1;32m   6259\u001b[0m     \u001b[38;5;66;03m# of an empty dict is 50x more expensive than the empty check.\u001b[39;00m\n\u001b[1;32m   6260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;241m=\u001b[39m deepcopy(other\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m-> 6262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mallows_duplicate_labels \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mallows_duplicate_labels\n\u001b[1;32m   6263\u001b[0m \u001b[38;5;66;03m# For subclasses using _metadata.\u001b[39;00m\n\u001b[1;32m   6264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(other\u001b[38;5;241m.\u001b[39m_metadata):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/pandas/core/flags.py:55\u001b[0m, in \u001b[0;36mFlags.allows_duplicate_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_duplicate_labels \u001b[38;5;241m=\u001b[39m allows_duplicate_labels\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(obj)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallows_duplicate_labels\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    Whether this object allows duplicate labels.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    a        [0, 1]\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_duplicate_labels\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# inference on finetuned model - test data\n",
    "inference(test_data, test_dfs, model_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4890481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference on wtq model - test data\n",
    "inference(test_data, test_dfs, model_wtq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see if finetuning was effective (for bugs) on train set\n",
    "# inference on finetuned model - train data\n",
    "inference(train_df, train_datasets, model_loaded)\n",
    "\n",
    "# inference on wtq model - train data\n",
    "#inference(train_df, train_datasets, model_wtq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4b9ea",
   "metadata": {},
   "source": [
    "Report accuracy train and dev (x-axis epoch, and y-axis loss) -> jsut show that I am thinking about overfitting\n",
    "Run error analysis on answer length by accuracy \n",
    "fix and and train data split\n",
    "talk about if I had more time... this is what I would have done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d1bbc",
   "metadata": {},
   "source": [
    "Observations \n",
    "- the aggregation operator is often wrong, but still gets the right answer\n",
    "    - for example when looking for a max value, chooses the AVERAGE operator, but only on one cell so still correct\n",
    "- my finetuned model (on toy_df_vw) did not work I do not know why\n",
    "    - gets almost nothing right \n",
    "    - when I test on my train set\n",
    "    - I think that adding the extra coordinates is screwing with the model\n",
    "            - Number of Questions:  89\n",
    "            - Overall Accuracy:  0.10112359550561797\n",
    "            - Number Accuracy:  0.022727272727272728\n",
    "            - Category Accuracy:  0.08888888888888889\n",
    "            - NONE Accuracy: 0.09259259259259259\n",
    "            - Agg Accuracy: 0.12903225806451613\n",
    "            \n",
    "    - the non-fintuned wtq version was this:\n",
    "            - Number of Questions:  89\n",
    "            - Overall Accuracy:  0.23595505617977527\n",
    "            - Number Accuracy:  0.022727272727272728\n",
    "            - Category Accuracy:  0.24444444444444444\n",
    "            - NONE Accuracy: 0.2727272727272727\n",
    "            - Agg Accuracy: 0.20454545454545456"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d2bbe",
   "metadata": {},
   "source": [
    "Things to do \n",
    "- try to train on the df_v2 for 5 epochs\n",
    "- try to train on both versions of train data with altered questions\n",
    "- train for 6 or 7 epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32481fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a46c451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### test on: 005_NYC.csv ####################\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 011_SF.csv ####################\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.26881720430107525\n",
      "Number Accuracy:  0.29545454545454547\n",
      "Category Accuracy:  0.24489795918367346\n",
      "NONE Accuracy: 0.2765957446808511\n",
      "Agg Accuracy: 0.2608695652173913\n",
      "\n",
      "#################### test on: 005_NYC.csv ####################\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 011_SF.csv ####################\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.26881720430107525\n",
      "Number Accuracy:  0.29545454545454547\n",
      "Category Accuracy:  0.24489795918367346\n",
      "NONE Accuracy: 0.2765957446808511\n",
      "Agg Accuracy: 0.2608695652173913\n",
      "\n",
      "#################### test on: 037_Ted.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 038_Stroke.csv ####################\n",
      "#################### test on: 036_US.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 035_Billboard.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 040_Speed.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 039_Happy.csv ####################\n",
      "          CORRECT!\n",
      "\n",
      "Number of Questions:  49\n",
      "Overall Accuracy:  0.4489795918367347\n",
      "Number Accuracy:  0.4583333333333333\n",
      "Category Accuracy:  0.44\n",
      "NONE Accuracy: 0.46153846153846156\n",
      "Agg Accuracy: 0.43478260869565216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation wtq\n",
    "wtq = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "inference(train_df, train_datasets, wtq) # toy_df\n",
    "inference(train_df_v2, train_datasets, wtq) # toy_df_v2\n",
    "inference(test_data, test_dfs, wtq) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9e5e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### test on: 005_NYC.csv ####################\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "#################### test on: 011_SF.csv ####################\n",
      "          CORRECT!\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.10752688172043011\n",
      "Number Accuracy:  0.09090909090909091\n",
      "Category Accuracy:  0.12244897959183673\n",
      "NONE Accuracy: 0.1\n",
      "Agg Accuracy: 0.12121212121212122\n",
      "\n",
      "#################### test on: 005_NYC.csv ####################\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "#################### test on: 011_SF.csv ####################\n",
      "          CORRECT!\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.10752688172043011\n",
      "Number Accuracy:  0.09090909090909091\n",
      "Category Accuracy:  0.12244897959183673\n",
      "NONE Accuracy: 0.1\n",
      "Agg Accuracy: 0.12121212121212122\n",
      "\n",
      "#################### test on: 037_Ted.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 038_Stroke.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 036_US.csv ####################\n",
      "#################### test on: 035_Billboard.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 040_Speed.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 039_Happy.csv ####################\n",
      "\n",
      "Number of Questions:  49\n",
      "Overall Accuracy:  0.10204081632653061\n",
      "Number Accuracy:  0.16666666666666666\n",
      "Category Accuracy:  0.04\n",
      "NONE Accuracy: 0.034482758620689655\n",
      "Agg Accuracy: 0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation wtq_finetune\n",
    "wtq_finetune = TapasForQuestionAnswering.from_pretrained(\"models/wtq_finetune\")\n",
    "inference(train_df, train_datasets, wtq_finetune) # toy_df\n",
    "inference(train_df_v2, train_datasets, wtq_finetune) # toy_df_v2\n",
    "inference(test_data, test_dfs, wtq_finetune) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9f485f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### test on: 005_NYC.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "#################### test on: 011_SF.csv ####################\n",
      "          CORRECT!\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.24731182795698925\n",
      "Number Accuracy:  0.18181818181818182\n",
      "Category Accuracy:  0.30612244897959184\n",
      "NONE Accuracy: 0.30612244897959184\n",
      "Agg Accuracy: 0.18181818181818182\n",
      "\n",
      "#################### test on: 005_NYC.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "#################### test on: 011_SF.csv ####################\n",
      "          CORRECT!\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.24731182795698925\n",
      "Number Accuracy:  0.18181818181818182\n",
      "Category Accuracy:  0.30612244897959184\n",
      "NONE Accuracy: 0.30612244897959184\n",
      "Agg Accuracy: 0.18181818181818182\n",
      "\n",
      "#################### test on: 037_Ted.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 038_Stroke.csv ####################\n",
      "#################### test on: 036_US.csv ####################\n",
      "#################### test on: 035_Billboard.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 040_Speed.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 039_Happy.csv ####################\n",
      "          CORRECT!\n",
      "\n",
      "Number of Questions:  49\n",
      "Overall Accuracy:  0.14285714285714285\n",
      "Number Accuracy:  0.20833333333333334\n",
      "Category Accuracy:  0.08\n",
      "NONE Accuracy: 0.08\n",
      "Agg Accuracy: 0.20833333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation wtq_finetune_a\n",
    "wtq_finetune_a = TapasForQuestionAnswering.from_pretrained(\"models/wtq_finetune_a\")\n",
    "inference(train_df, train_datasets, wtq_finetune_a) # toy_df\n",
    "inference(train_df_v2, train_datasets, wtq_finetune_a) # toy_df_v2\n",
    "inference(test_data, test_dfs, wtq_finetune_a) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19f49bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### test on: 005_NYC.csv ####################\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 011_SF.csv ####################\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.23655913978494625\n",
      "Number Accuracy:  0.3181818181818182\n",
      "Category Accuracy:  0.16326530612244897\n",
      "NONE Accuracy: 0.20833333333333334\n",
      "Agg Accuracy: 0.26666666666666666\n",
      "\n",
      "#################### test on: 005_NYC.csv ####################\n",
      "#################### test on: 007_Fifa.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 019_Aircraft.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 002_Titanic.csv ####################\n",
      "#################### test on: 001_Forbes.csv ####################\n",
      "#################### test on: 004_Taxi.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 013_Roller.csv ####################\n",
      "#################### test on: 008_Tornados.csv ####################\n",
      "#################### test on: 017_Hacker.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 010_ECommerce.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 012_Heart.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 018_Staff.csv ####################\n",
      "#################### test on: 015_Food.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 011_SF.csv ####################\n",
      "\n",
      "Number of Questions:  93\n",
      "Overall Accuracy:  0.23655913978494625\n",
      "Number Accuracy:  0.3181818181818182\n",
      "Category Accuracy:  0.16326530612244897\n",
      "NONE Accuracy: 0.20833333333333334\n",
      "Agg Accuracy: 0.26666666666666666\n",
      "\n",
      "#################### test on: 037_Ted.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 038_Stroke.csv ####################\n",
      "#################### test on: 036_US.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 035_Billboard.csv ####################\n",
      "          CORRECT!\n",
      "          CORRECT!\n",
      "#################### test on: 040_Speed.csv ####################\n",
      "          CORRECT!\n",
      "#################### test on: 039_Happy.csv ####################\n",
      "          CORRECT!\n",
      "\n",
      "Number of Questions:  49\n",
      "Overall Accuracy:  0.46938775510204084\n",
      "Number Accuracy:  0.4583333333333333\n",
      "Category Accuracy:  0.48\n",
      "NONE Accuracy: 0.52\n",
      "Agg Accuracy: 0.4166666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation wtq_finetune_five_epoch_lower_learn schedule\n",
    "wtq_finetune_five = TapasForQuestionAnswering.from_pretrained(\"models/wtq_finetune_five_epoch_lower_learn_schedule\")\n",
    "inference(train_df, train_datasets, wtq_finetune_five) # toy_df\n",
    "inference(train_df_v2, train_datasets, wtq_finetune_five) # toy_df_v2\n",
    "inference(test_data, test_dfs, wtq_finetune_five) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37980356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
