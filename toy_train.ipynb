{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9797c22a",
   "metadata": {},
   "source": [
    "File to train on the toy_df.csv (that came from the 001_Forbes Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05b024a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import TapasConfig, TapasForQuestionAnswering, TapasTokenizer, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96525ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load in tokenizer\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91d0da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the string representation to a list of tuples\n",
    "def parse_answer_coords(coords_str):\n",
    "    try:\n",
    "        # Safely evaluate the string to a Python object\n",
    "        coords = ast.literal_eval(coords_str)\n",
    "        \n",
    "        # Ensure the result is a list of tuples with integers\n",
    "        if isinstance(coords, list) and all(\n",
    "            isinstance(coord, (tuple, list)) and len(coord) == 2 and all(isinstance(x, int) for x in coord)\n",
    "            for coord in coords\n",
    "        ):\n",
    "            return [tuple(coord) for coord in coords]  # Convert lists to tuples if needed\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid format for answer_coords: {coords_str}\")\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        raise ValueError(f\"Error parsing answer_coords: {coords_str}. Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20dcf48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to tokenizer dataset\n",
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = self.process_answer_coords_column(data)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.table_csv_path = 'data/'\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        print(item.answer_coords)\n",
    "        table = pd.read_csv(self.table_csv_path + item.dataset).astype(\n",
    "            str\n",
    "        )  # be sure to make your table data text only\n",
    "        encoding = self.tokenizer(\n",
    "            table=table,\n",
    "            queries=item.question,\n",
    "            answer_coordinates=item.answer_coords,\n",
    "            answer_text=item.sample_answer,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # remove the batch dimension which the tokenizer adds by default\n",
    "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        # add the float_answer which is also required (weak supervision for aggregation case)\n",
    "        encoding[\"float_answer\"] = torch.tensor(item.float_answer)\n",
    "        return encoding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # change answer_coords from strings\n",
    "    def process_answer_coords_column(self, data, column_name=\"answer_coords\"):\n",
    "        if column_name not in data.columns:\n",
    "            raise ValueError(f\"Column '{column_name}' does not exist in the dataset.\")\n",
    "\n",
    "        def parse_answer_coords(coords_str):\n",
    "            try:\n",
    "                coords = ast.literal_eval(coords_str)\n",
    "                if isinstance(coords, list) and all(\n",
    "                    isinstance(coord, (tuple, list)) and len(coord) == 2 and all(isinstance(x, int) for x in coord)\n",
    "                    for coord in coords\n",
    "                ):\n",
    "                    return [tuple(coord) for coord in coords]\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid format for answer_coords: {coords_str}\")\n",
    "            except (ValueError, SyntaxError) as e:\n",
    "                raise ValueError(f\"Error parsing answer_coords: {coords_str}. Details: {e}\")\n",
    "        data[column_name] = data[column_name].apply(parse_answer_coords)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afb145ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/_zcz3_s54kz_1zxxwgs414pw0000gn/T/ipykernel_57537/94817247.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_name] = data[column_name].apply(parse_answer_coords)\n"
     ]
    }
   ],
   "source": [
    "#TODO: generalize so that we can pull the unique csv names from the new dataset and filter through them to create a dataloader for each\n",
    "\n",
    "# load in toy_df, tokenize and place in dataloader\n",
    "csv_path = 'data/toy_df.csv'\n",
    "toy_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Apply the function to the answer_coords column\n",
    "\n",
    "\n",
    "# split into train and dev\n",
    "toy_df_train = toy_df.iloc[[0, 2, 3, 4]]\n",
    "toy_df_dev = toy_df.iloc[[1, 5]]\n",
    "\n",
    "# load train dataloader\n",
    "train_dataset = TableDataset(toy_df_train, tokenizer)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2)\n",
    "\n",
    "# load dev dataloader\n",
    "dev_dataset = TableDataset(toy_df_dev, tokenizer)\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "203843e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['aggregation_classifier.bias', 'aggregation_classifier.weight', 'column_output_bias', 'column_output_weights', 'output_bias', 'output_weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load in WTQ model\n",
    "config = TapasConfig(\n",
    "    num_aggregation_labels=4,\n",
    "    use_answer_as_supervision=True,\n",
    "    answer_loss_cutoff=0.664694,\n",
    "    cell_selection_preference=0.207951,\n",
    "    huber_loss_delta=0.121194,\n",
    "    init_cell_selection_weights_to_zero=True,\n",
    "    select_one_column=True,\n",
    "    allow_empty_column_selection=False,\n",
    "    temperature=0.0352513,\n",
    ")\n",
    "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f4b8b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11, 5)]\n",
      "[(7, 8)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=tensor(2.2632, grad_fn=<AddBackward0>), logits=tensor([[-10000., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
      "        [-10000., -10000., -10000.,  ..., -10000., -10000., -10000.]],\n",
      "       grad_fn=<ViewBackward0>), logits_aggregation=tensor([[ 0.2091,  0.1775, -0.0712,  0.3980],\n",
      "        [ 0.0871,  0.1593, -0.1162,  0.3574]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "[(18, 10)]\n",
      "[(0, 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=tensor(3.9879, grad_fn=<AddBackward0>), logits=tensor([[-10000.1250, -10000.1250, -10000.1250,  ..., -10000.1250,\n",
      "         -10000.1250, -10000.1250],\n",
      "        [-10000.1260, -10000.1260, -10000.1260,  ..., -10000.1260,\n",
      "         -10000.1260, -10000.1260]], grad_fn=<ViewBackward0>), logits_aggregation=tensor([[ 0.2936, -0.3012, -0.4651, -0.0207],\n",
      "        [ 0.2969, -0.3606, -0.4653, -0.0208]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "[(11, 5)]\n",
      "[(7, 8)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=tensor(1.8844, grad_fn=<AddBackward0>), logits=tensor([[-10000.2402, -10000.2402, -10000.2402,  ..., -10000.2402,\n",
      "         -10000.2402, -10000.2402],\n",
      "        [-10000.2393, -10000.2393, -10000.2393,  ..., -10000.2393,\n",
      "         -10000.2393, -10000.2393]], grad_fn=<ViewBackward0>), logits_aggregation=tensor([[ 0.5836, -0.1453, -0.3825,  0.1192],\n",
      "        [ 0.6485, -0.1279, -0.4293,  0.1109]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "[(18, 10)]\n",
      "[(0, 4)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=tensor(3.6453, grad_fn=<AddBackward0>), logits=tensor([[-10000.2979, -10000.2979, -10000.2979,  ..., -10000.2979,\n",
      "         -10000.2979, -10000.2979],\n",
      "        [-10000.2988, -10000.2988, -10000.2988,  ..., -10000.2988,\n",
      "         -10000.2988, -10000.2988]], grad_fn=<ViewBackward0>), logits_aggregation=tensor([[ 0.8348, -0.1410, -0.2435,  0.3021],\n",
      "        [ 0.8507, -0.0115, -0.3043,  0.3783]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "# finetune the WTQ model\n",
    "model.train()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    for batch in train_dataloader:\n",
    "        # get the inputs;\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        token_type_ids = batch[\"token_type_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        numeric_values = batch[\"numeric_values\"]\n",
    "        numeric_values_scale = batch[\"numeric_values_scale\"]\n",
    "        float_answer = batch[\"float_answer\"]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels,\n",
    "            numeric_values=numeric_values,\n",
    "            numeric_values_scale=numeric_values_scale,\n",
    "            float_answer=float_answer,\n",
    "        )\n",
    "        print(outputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print('Done Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11b53811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selfMade</th>\n",
       "      <th>finalWorth</th>\n",
       "      <th>city</th>\n",
       "      <th>title</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>rank</th>\n",
       "      <th>philanthropyScore</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>7800</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Chairman</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>media, automotive</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1700</td>\n",
       "      <td>Ningbo</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1729</td>\n",
       "      <td>nan</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>precision machinery</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>2000</td>\n",
       "      <td>Wuhan</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1513</td>\n",
       "      <td>nan</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>real estate</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1100</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2448</td>\n",
       "      <td>nan</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>pharmaceuticals</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>3300</td>\n",
       "      <td>Sao Jose dos Pinhais</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>72.0</td>\n",
       "      <td>913</td>\n",
       "      <td>nan</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "      <td>cosmetics</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>5200</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>nan</td>\n",
       "      <td>F</td>\n",
       "      <td>79.0</td>\n",
       "      <td>523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>media, automotive</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>4700</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>54.0</td>\n",
       "      <td>601</td>\n",
       "      <td>nan</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>financial services</td>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>5300</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>51.0</td>\n",
       "      <td>509</td>\n",
       "      <td>nan</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>restaurants</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>2000</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1513</td>\n",
       "      <td>nan</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>real estate finance</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>2600</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>M</td>\n",
       "      <td>nan</td>\n",
       "      <td>1196</td>\n",
       "      <td>nan</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>diversified</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>1300</td>\n",
       "      <td>Jinan</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>nan</td>\n",
       "      <td>2190</td>\n",
       "      <td>nan</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Semiconductor materials</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>1400</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Cofounder</td>\n",
       "      <td>M</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2076</td>\n",
       "      <td>nan</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>fintech</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>1100</td>\n",
       "      <td>Foshan</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2448</td>\n",
       "      <td>nan</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>soy sauce</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>1400</td>\n",
       "      <td>New York</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2076</td>\n",
       "      <td>nan</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>WeWork</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>7900</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>nan</td>\n",
       "      <td>F</td>\n",
       "      <td>61.0</td>\n",
       "      <td>288</td>\n",
       "      <td>nan</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>candy, pet food</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>2500</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1238</td>\n",
       "      <td>nan</td>\n",
       "      <td>Diversified</td>\n",
       "      <td>diversified</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>4400</td>\n",
       "      <td>New York</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>80.0</td>\n",
       "      <td>654</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Media &amp; Entertainment</td>\n",
       "      <td>online media</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>1400</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2076</td>\n",
       "      <td>nan</td>\n",
       "      <td>Service</td>\n",
       "      <td>education</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>1300</td>\n",
       "      <td>London</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2190</td>\n",
       "      <td>nan</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "      <td>fashion retailer</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>True</td>\n",
       "      <td>1700</td>\n",
       "      <td>Hengshui</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1729</td>\n",
       "      <td>nan</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>beverages</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   selfMade finalWorth                  city      title gender   age  rank  \\\n",
       "0     False       7800               Atlanta  Chairman       M  74.0   296   \n",
       "1      True       1700                Ningbo        nan      M  86.0  1729   \n",
       "2      True       2000                 Wuhan        nan      M  49.0  1513   \n",
       "3      True       1100             São Paulo        nan      M  69.0  2448   \n",
       "4      True       3300  Sao Jose dos Pinhais        nan      M  72.0   913   \n",
       "5     False       5200           Southampton        nan      F  79.0   523   \n",
       "6     False       4700                Taipei        nan      M  54.0   601   \n",
       "7      True       5300             Singapore        nan      M  51.0   509   \n",
       "8      True       2000               Toronto        nan      M  65.0  1513   \n",
       "9     False       2600                 Dubai    Athlete      M   nan  1196   \n",
       "10     True       1300                 Jinan        nan      M   nan  2190   \n",
       "11     True       1400         San Francisco  Cofounder      M  32.0  2076   \n",
       "12     True       1100                Foshan        nan      M  52.0  2448   \n",
       "13     True       1400              New York        nan      M  43.0  2076   \n",
       "14    False       7900            Alexandria        nan      F  61.0   288   \n",
       "15     True       2500                 Cairo        nan      M  74.0  1238   \n",
       "16     True       4400              New York        nan      M  80.0   654   \n",
       "17    False       1400             Bangalore        nan      M  49.0  2076   \n",
       "18     True       1300                London        nan      M  96.0  2190   \n",
       "19     True       1700              Hengshui        nan      M  57.0  1729   \n",
       "\n",
       "   philanthropyScore               category                   source  \\\n",
       "0                2.0  Media & Entertainment        media, automotive   \n",
       "1                nan          Manufacturing      precision machinery   \n",
       "2                nan            Real Estate              real estate   \n",
       "3                nan            Diversified          pharmaceuticals   \n",
       "4                nan       Fashion & Retail                cosmetics   \n",
       "5                1.0  Media & Entertainment        media, automotive   \n",
       "6                nan  Finance & Investments       financial services   \n",
       "7                nan        Food & Beverage              restaurants   \n",
       "8                nan  Finance & Investments      real estate finance   \n",
       "9                nan            Diversified              diversified   \n",
       "10               nan          Manufacturing  Semiconductor materials   \n",
       "11               nan  Finance & Investments                  fintech   \n",
       "12               nan        Food & Beverage                soy sauce   \n",
       "13               nan            Real Estate                   WeWork   \n",
       "14               nan        Food & Beverage          candy, pet food   \n",
       "15               nan            Diversified              diversified   \n",
       "16               3.0  Media & Entertainment             online media   \n",
       "17               nan                Service                education   \n",
       "18               nan       Fashion & Retail         fashion retailer   \n",
       "19               nan        Food & Beverage                beverages   \n",
       "\n",
       "                 country  \n",
       "0          United States  \n",
       "1                  China  \n",
       "2                  China  \n",
       "3                 Brazil  \n",
       "4                 Brazil  \n",
       "5          United States  \n",
       "6                 Taiwan  \n",
       "7              Singapore  \n",
       "8                 Canada  \n",
       "9   United Arab Emirates  \n",
       "10                 China  \n",
       "11         United States  \n",
       "12                 China  \n",
       "13         United States  \n",
       "14         United States  \n",
       "15                 Egypt  \n",
       "16         United States  \n",
       "17                 India  \n",
       "18        United Kingdom  \n",
       "19                 China  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What's the rank of the wealthiest non-self-made billionaire?\n",
      "Predicted answer: SUM > \n",
      "What's the source of wealth for the youngest billionaire?\n",
      "Predicted answer: SUM > \n"
     ]
    }
   ],
   "source": [
    "# try inference\n",
    "\n",
    "# data is the 001_forbes.csv\n",
    "# inputs is the tokenized inputs (dev, but just queries and table)\n",
    "\n",
    "table = pd.read_csv('data/001_Forbes.csv').astype(str)\n",
    "queries = list(toy_df_dev['question'])\n",
    "\n",
    "inputs = tokenizer(\n",
    "    table = table,\n",
    "    queries = queries,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n",
    ")\n",
    "\n",
    "# print results:\n",
    "id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3: \"COUNT\"}\n",
    "aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n",
    "\n",
    "answers = []\n",
    "for coordinates in predicted_answer_coordinates:\n",
    "    if len(coordinates) == 1:\n",
    "        # only a single cell:\n",
    "        answers.append(table.iat[coordinates[0]])\n",
    "    else:\n",
    "        # multiple cells\n",
    "        cell_values = []\n",
    "        for coordinate in coordinates:\n",
    "            cell_values.append(table.iat[coordinate])\n",
    "        answers.append(\", \".join(cell_values))\n",
    "\n",
    "display(table)\n",
    "print(\"\")\n",
    "for query, answer, predicted_agg in zip(queries, answers, aggregation_predictions_string):\n",
    "    print(query)\n",
    "    if predicted_agg == \"NONE\":\n",
    "        print(\"Predicted answer: \" + answer)\n",
    "    else:\n",
    "        print(\"Predicted answer: \" + predicted_agg + \" > \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57707f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "{'input_ids': tensor([[ 101, 2054, 1005,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 1005,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "outputs\n",
      "TableQuestionAnsweringOutput(loss=None, logits=tensor([[-88.7000, -88.7000, -88.7000,  ..., -88.7000, -88.7000, -88.7000],\n",
      "        [-88.7000, -88.7000, -88.7000,  ..., -88.7000, -88.7000, -88.7000]],\n",
      "       grad_fn=<ViewBackward0>), logits_aggregation=tensor([[-0.3734,  0.2418, -0.0422, -0.6087],\n",
      "        [-0.2633,  0.0688, -0.0211, -0.3979]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "Logits:\n",
      "tensor([[-88.7000, -88.7000, -88.7000,  ..., -88.7000, -88.7000, -88.7000],\n",
      "        [-88.7000, -88.7000, -88.7000,  ..., -88.7000, -88.7000, -88.7000]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Aggregation Logits:\n",
      "tensor([[-0.3734,  0.2418, -0.0422, -0.6087],\n",
      "        [-0.2633,  0.0688, -0.0211, -0.3979]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"inputs\")\n",
    "print(inputs)\n",
    "print(\"outputs\")\n",
    "print(outputs)\n",
    "print(\"Logits:\")\n",
    "print(outputs.logits)\n",
    "print(\"Aggregation Logits:\")\n",
    "print(outputs.logits_aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e402001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer Coordinates:\n",
      "[[], []]\n",
      "Predicted Aggregation Indices:\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n",
    ")\n",
    "\n",
    "# Print predicted answer coordinates and aggregation indices\n",
    "print(\"Predicted Answer Coordinates:\")\n",
    "print(predicted_answer_coordinates)\n",
    "print(\"Predicted Aggregation Indices:\")\n",
    "print(predicted_aggregation_indices)\n",
    "\n",
    "# apperently this error might be due to not crossing a confidence threshold so that it will not give valid answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57acb190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs Shape: torch.Size([2, 512])\n",
      "Token Type IDs Shape: torch.Size([2, 512, 7])\n",
      "Attention Mask Shape: torch.Size([2, 512])\n",
      "Logits Shape: torch.Size([2, 512])\n",
      "Aggregation Logits Shape: torch.Size([2, 4])\n",
      "Logits: tensor([[-88.7000, -88.7000, -88.7000,  ..., -88.7000, -88.7000, -88.7000],\n",
      "        [-88.7000, -88.7000, -88.7000,  ..., -88.7000, -88.7000, -88.7000]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Aggregation Logits: tensor([[-0.3734,  0.2418, -0.0422, -0.6087],\n",
      "        [-0.2633,  0.0688, -0.0211, -0.3979]], grad_fn=<AddmmBackward0>)\n",
      "Predicted Coordinates: [[], []]\n",
      "Predicted Aggregation Indices: [1, 1]\n",
      "[(11, 5)]\n",
      "[(7, 8)]\n",
      "torch.Size([2, 512])\n",
      "tensor([32., nan], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs Shape:\", inputs['input_ids'].shape)\n",
    "print(\"Token Type IDs Shape:\", inputs['token_type_ids'].shape)\n",
    "print(\"Attention Mask Shape:\", inputs['attention_mask'].shape)\n",
    "print(\"Logits Shape:\", outputs.logits.shape)\n",
    "print(\"Aggregation Logits Shape:\", outputs.logits_aggregation.shape)\n",
    "print(\"Logits:\", outputs.logits)\n",
    "print(\"Aggregation Logits:\", outputs.logits_aggregation)\n",
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n",
    ")\n",
    "print(\"Predicted Coordinates:\", predicted_answer_coordinates)\n",
    "print(\"Predicted Aggregation Indices:\", predicted_aggregation_indices)\n",
    "for batch in train_dataloader:\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    print(batch[\"float_answer\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0390c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
