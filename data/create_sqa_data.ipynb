{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a836e767",
   "metadata": {},
   "source": [
    "We need to format our data into SQA format and save into a csv/tsv for the finetuning which needs:\n",
    "\n",
    "id: optional, id of the table-question pair, for bookkeeping purposes.\n",
    "\n",
    "annotator: optional, id of the person who annotated the table-question pair, for bookkeeping purposes.\n",
    "\n",
    "position: integer indicating if the question is the first, second, third,… related to the table. Only required in case of conversational setup (SQA). You don’t need this column in case you’re going for WTQ/WikiSQL-supervised.\n",
    "\n",
    "question: string\n",
    "\n",
    "table_file: string, name of a csv file containing the tabular data\n",
    "answer_coordinates: list of one or more tuples (each tuple being a cell coordinate, i.e. row, column pair that is part of the answer)\n",
    "\n",
    "answer_text: list of one or more strings (each string being a cell value that is part of the answer)\n",
    "aggregation_label: index of the aggregation operator. Only required in case of strong supervision for aggregation (the WikiSQL-supervised case)\n",
    "\n",
    "float_answer: the float answer to the question, if there is one (np.nan if there isn’t). Only required in case of weak supervision for aggregation (such as WTQ and WikiSQL)\n",
    "\n",
    "the tables refered to in the table_file area should be saved in a folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2c28430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import TapasTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d509af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc60e4179834386a4d62b4e4143176c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42d2706d671487ab7bf7466ba04c5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d29b3189884472da833e6a95853c898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfbb1d3cea24260996c4792290e8d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in all qa (train and dev)\n",
    "semeval_train_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"train\")\n",
    "semeval_dev_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd4d5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique dataset names\n",
    "df_ids = list(set(semeval_train_qa[\"dataset\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e14f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the forbes dataframe (pandas dataframes)\n",
    "forbes_id = df_ids[8]\n",
    "forbes_df = pd.read_parquet(f\"hf://datasets/cardiffnlp/databench/data/{forbes_id}/all.parquet\")\n",
    "forbes_qa = pd.read_parquet(f\"hf://datasets/cardiffnlp/databench/data/{forbes_id}/qa.parquet\")\n",
    "forbes_sample_df = pd.read_parquet(f\"hf://datasets/cardiffnlp/databench/data/{forbes_id}/sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "660124a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only questions that have a numerical answer\n",
    "forbes_qa_num = forbes_qa[forbes_qa['type'] == 'number']\n",
    "aggregartion_ops = ['SUM', 'COUNT', 'AVERAGE', 'NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ab3268b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>type</th>\n",
       "      <th>columns_used</th>\n",
       "      <th>column_types</th>\n",
       "      <th>sample_answer</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the age of the youngest billionaire?</td>\n",
       "      <td>19.0</td>\n",
       "      <td>number</td>\n",
       "      <td>['age']</td>\n",
       "      <td>['number[UInt8]']</td>\n",
       "      <td>32.0</td>\n",
       "      <td>001_Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many billionaires are there from the 'Tech...</td>\n",
       "      <td>343</td>\n",
       "      <td>number</td>\n",
       "      <td>['category']</td>\n",
       "      <td>['category']</td>\n",
       "      <td>0</td>\n",
       "      <td>001_Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What's the total worth of billionaires in the ...</td>\n",
       "      <td>583600</td>\n",
       "      <td>number</td>\n",
       "      <td>['category', 'finalWorth']</td>\n",
       "      <td>['category', 'number[uint32]']</td>\n",
       "      <td>0</td>\n",
       "      <td>001_Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How many billionaires have a philanthropy scor...</td>\n",
       "      <td>25</td>\n",
       "      <td>number</td>\n",
       "      <td>['philanthropyScore']</td>\n",
       "      <td>['number[UInt8]']</td>\n",
       "      <td>0</td>\n",
       "      <td>001_Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What's the rank of the wealthiest non-self-mad...</td>\n",
       "      <td>3</td>\n",
       "      <td>number</td>\n",
       "      <td>['selfMade', 'rank']</td>\n",
       "      <td>['boolean', 'number[uint16]']</td>\n",
       "      <td>288</td>\n",
       "      <td>001_Forbes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  answer    type  \\\n",
       "5       What is the age of the youngest billionaire?    19.0  number   \n",
       "6  How many billionaires are there from the 'Tech...     343  number   \n",
       "7  What's the total worth of billionaires in the ...  583600  number   \n",
       "8  How many billionaires have a philanthropy scor...      25  number   \n",
       "9  What's the rank of the wealthiest non-self-mad...       3  number   \n",
       "\n",
       "                 columns_used                    column_types sample_answer  \\\n",
       "5                     ['age']               ['number[UInt8]']          32.0   \n",
       "6                ['category']                    ['category']             0   \n",
       "7  ['category', 'finalWorth']  ['category', 'number[uint32]']             0   \n",
       "8       ['philanthropyScore']               ['number[UInt8]']             0   \n",
       "9        ['selfMade', 'rank']   ['boolean', 'number[uint16]']           288   \n",
       "\n",
       "      dataset  \n",
       "5  001_Forbes  \n",
       "6  001_Forbes  \n",
       "7  001_Forbes  \n",
       "8  001_Forbes  \n",
       "9  001_Forbes  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add answer coordinates to the table \n",
    "forbes_qa_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "416585dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f1/_zcz3_s54kz_1zxxwgs414pw0000gn/T/ipykernel_33960/1226919560.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forbes_qa_num['answer_coords'] = answer_coords\n",
      "/var/folders/f1/_zcz3_s54kz_1zxxwgs414pw0000gn/T/ipykernel_33960/1226919560.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  forbes_qa_num['agg_ops'] = agg_ops\n"
     ]
    }
   ],
   "source": [
    "# find all of the answer coordinates\n",
    "\n",
    "# youngest billionare\n",
    "row_index = forbes_df['age'].idxmin()\n",
    "col_index = forbes_df.columns.get_loc('age')\n",
    "location_one = [(row_index, col_index)]\n",
    "\n",
    "# number of tech billionaires\n",
    "row_index = forbes_df.index[forbes_df['category'] == 'Technology'].tolist()\n",
    "col_index = forbes_df.columns.get_loc('category')\n",
    "location_two = [(row, col_index) for row in row_index]\n",
    "\n",
    "# total worth of billionares in Automotive category\n",
    "row_index = range(len(forbes_df))\n",
    "col_index = forbes_df.columns.get_loc('category')\n",
    "location_three = [(row, col_index) for row in row_index]\n",
    "\n",
    "# number of billionares with philanthropy score over 3 \n",
    "row_index = forbes_df.index[forbes_df['philanthropyScore'] > 3].tolist()\n",
    "col_index = forbes_df.columns.get_loc('philanthropyScore')\n",
    "location_four = [(row, col_index) for row in row_index]\n",
    "\n",
    "# rank of wealthiest non-self-made billionare\n",
    "row_index = forbes_df[forbes_df['selfMade'] == False]['finalWorth'].idxmax()\n",
    "col_index = forbes_df.columns.get_loc('rank')\n",
    "location_five = [(row_index, col_index)]\n",
    "\n",
    "answer_coords = [location_one, location_two, location_three, location_four, location_five]\n",
    "forbes_qa_num['answer_coords'] = answer_coords\n",
    "\n",
    "agg_ops = [3, 1, 0, 1, 0]\n",
    "forbes_qa_num['agg_ops'] = agg_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86de934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank                              uint16\n",
       "personName                      category\n",
       "age                              float64\n",
       "finalWorth                        uint32\n",
       "category                        category\n",
       "source                          category\n",
       "country                         category\n",
       "state                           category\n",
       "city                            category\n",
       "organization                    category\n",
       "selfMade                            bool\n",
       "gender                          category\n",
       "birthDate            datetime64[us, UTC]\n",
       "title                           category\n",
       "philanthropyScore                float64\n",
       "bio                               object\n",
       "about                             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this table now has the correct data (along with the data) to have inputs \n",
    "forbes_qa_num = forbes_qa_num.astype(str)\n",
    "forbes_qa_num['question'] = forbes_qa_num['question'].astype(str)\n",
    "forbes_qa_num.dtypes\n",
    "#forbes_qa_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e67939e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "queries input must of type `str` (single example), `List[str]` (batch or single pretokenized example). ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m answer_coords \u001b[38;5;241m=\u001b[39m forbes_qa_num[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_coords\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m answer_text \u001b[38;5;241m=\u001b[39m forbes_qa_num[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m     11\u001b[0m     table \u001b[38;5;241m=\u001b[39m table,\n\u001b[1;32m     12\u001b[0m     queries \u001b[38;5;241m=\u001b[39m queries,\n\u001b[1;32m     13\u001b[0m     answer_coordinates \u001b[38;5;241m=\u001b[39m answer_coords,\n\u001b[1;32m     14\u001b[0m     answer_text \u001b[38;5;241m=\u001b[39m answer_text,\n\u001b[1;32m     15\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m inputs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:567\u001b[0m, in \u001b[0;36mTapasTokenizer.__call__\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         valid_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_query:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries input must of type `str` (single example), `List[str]` (batch or single pretokenized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m example). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     )\n\u001b[1;32m    571\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(queries, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "\u001b[0;31mValueError\u001b[0m: queries input must of type `str` (single example), `List[str]` (batch or single pretokenized example). "
     ]
    }
   ],
   "source": [
    "# example of how to load in model and then format the data\n",
    "model_name = \"google/tapas-base\"\n",
    "tokenizer = TapasTokenizer.from_pretrained(model_name)\n",
    "\n",
    "table = forbes_df\n",
    "queries = forbes_qa_num['question']\n",
    "answer_coords = forbes_qa_num['answer_coords']\n",
    "answer_text = forbes_qa_num['answer']\n",
    "\n",
    "inputs = tokenizer(\n",
    "    table = table,\n",
    "    queries = queries,\n",
    "    answer_coordinates = answer_coords,\n",
    "    answer_text = answer_text,\n",
    "    padding = \"max_length\",\n",
    "    return_tensors = \"pt\",\n",
    ")\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "122e2302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee5f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
