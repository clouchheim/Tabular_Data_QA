{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a836e767",
   "metadata": {},
   "source": [
    "We need to format our data into SQA format and save into a csv/tsv for the finetuning which needs:\n",
    "\n",
    "id: optional, id of the table-question pair, for bookkeeping purposes.\n",
    "\n",
    "annotator: optional, id of the person who annotated the table-question pair, for bookkeeping purposes.\n",
    "\n",
    "position: integer indicating if the question is the first, second, third,… related to the table. Only required in case of conversational setup (SQA). You don’t need this column in case you’re going for WTQ/WikiSQL-supervised.\n",
    "\n",
    "question: string\n",
    "\n",
    "table_file: string, name of a csv file containing the tabular data\n",
    "answer_coordinates: list of one or more tuples (each tuple being a cell coordinate, i.e. row, column pair that is part of the answer)\n",
    "\n",
    "answer_text: list of one or more strings (each string being a cell value that is part of the answer)\n",
    "aggregation_label: index of the aggregation operator. Only required in case of strong supervision for aggregation (the WikiSQL-supervised case)\n",
    "\n",
    "float_answer: the float answer to the question, if there is one (np.nan if there isn’t). Only required in case of weak supervision for aggregation (such as WTQ and WikiSQL)\n",
    "\n",
    "the tables refered to in the table_file area should be saved in a folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c28430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import TapasTokenizer, TapasForQuestionAnswering, TapasConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d509af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6288135359684b47b89c7e9a168a7812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5a3702d9d04515ae2a166101cba2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bad4f9867841b7a5c4f946708b8917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f54cee38ffa45aa8e319b3986aba66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in all qa (train and dev)\n",
    "semeval_train_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"train\")\n",
    "semeval_dev_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2d2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of all of the train datasets\n",
    "dfs_train = list(set(semeval_train_qa['dataset']))\n",
    "dfs_train = sorted(dfs_train, key=lambda x: int(x.split('_')[0]))\n",
    "\n",
    "# get the names of all of the dev datasets\n",
    "dfs_dev = list(set(semeval_dev_qa['dataset']))\n",
    "dfs_dev = sorted(dfs_dev, key=lambda x: int(x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e14f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  001_Forbes\n",
      "CSV for ID 001_Forbes already exists. Skipping...\n",
      "Processing:  002_Titanic\n",
      "CSV for ID 002_Titanic already exists. Skipping...\n",
      "Processing:  003_Love\n",
      "CSV for ID 003_Love already exists. Skipping...\n",
      "Processing:  004_Taxi\n",
      "CSV for ID 004_Taxi already exists. Skipping...\n",
      "Processing:  005_NYC\n",
      "CSV for ID 005_NYC already exists. Skipping...\n",
      "Processing:  006_London\n",
      "CSV for ID 006_London already exists. Skipping...\n",
      "Processing:  007_Fifa\n",
      "CSV for ID 007_Fifa already exists. Skipping...\n",
      "Processing:  008_Tornados\n",
      "CSV for ID 008_Tornados already exists. Skipping...\n",
      "Processing:  009_Central\n",
      "CSV for ID 009_Central already exists. Skipping...\n",
      "Processing:  010_ECommerce\n",
      "CSV for ID 010_ECommerce already exists. Skipping...\n",
      "Processing:  011_SF\n",
      "CSV for ID 011_SF already exists. Skipping...\n",
      "Processing:  012_Heart\n",
      "CSV for ID 012_Heart already exists. Skipping...\n",
      "Processing:  013_Roller\n",
      "CSV for ID 013_Roller already exists. Skipping...\n",
      "Processing:  014_Airbnb\n",
      "CSV for ID 014_Airbnb already exists. Skipping...\n",
      "Processing:  015_Food\n",
      "CSV for ID 015_Food already exists. Skipping...\n",
      "Processing:  016_Holiday\n",
      "CSV for ID 016_Holiday already exists. Skipping...\n",
      "Processing:  017_Hacker\n",
      "CSV for ID 017_Hacker already exists. Skipping...\n",
      "Processing:  018_Staff\n",
      "CSV for ID 018_Staff already exists. Skipping...\n",
      "Processing:  019_Aircraft\n",
      "CSV for ID 019_Aircraft already exists. Skipping...\n",
      "Processing:  020_Real\n",
      "CSV for ID 020_Real already exists. Skipping...\n",
      "Processing:  021_Telco\n",
      "CSV for ID 021_Telco already exists. Skipping...\n",
      "Processing:  022_Airbnbs\n",
      "CSV for ID 022_Airbnbs already exists. Skipping...\n",
      "Processing:  023_Climate\n",
      "CSV for ID 023_Climate already exists. Skipping...\n",
      "Processing:  024_Salary\n",
      "CSV for ID 024_Salary already exists. Skipping...\n",
      "Processing:  025_Data\n",
      "CSV for ID 025_Data already exists. Skipping...\n",
      "Processing:  026_Predicting\n",
      "CSV for ID 026_Predicting already exists. Skipping...\n",
      "Processing:  027_Supermarket\n",
      "CSV for ID 027_Supermarket already exists. Skipping...\n",
      "Processing:  028_Predict\n",
      "CSV for ID 028_Predict already exists. Skipping...\n",
      "Processing:  029_NYTimes\n",
      "CSV for ID 029_NYTimes already exists. Skipping...\n",
      "Processing:  030_Professionals\n",
      "CSV for ID 030_Professionals already exists. Skipping...\n",
      "Processing:  031_Trustpilot\n",
      "CSV for ID 031_Trustpilot already exists. Skipping...\n",
      "Processing:  032_Delicatessen\n",
      "CSV for ID 032_Delicatessen already exists. Skipping...\n",
      "Processing:  033_Employee\n",
      "CSV for ID 033_Employee already exists. Skipping...\n",
      "Processing:  034_World\n",
      "CSV for ID 034_World already exists. Skipping...\n",
      "Processing:  035_Billboard\n",
      "CSV for ID 035_Billboard already exists. Skipping...\n",
      "Processing:  036_US\n",
      "CSV for ID 036_US already exists. Skipping...\n",
      "Processing:  037_Ted\n",
      "CSV for ID 037_Ted already exists. Skipping...\n",
      "Processing:  038_Stroke\n",
      "CSV for ID 038_Stroke already exists. Skipping...\n",
      "Processing:  039_Happy\n",
      "CSV for ID 039_Happy already exists. Skipping...\n",
      "Processing:  040_Speed\n",
      "CSV for ID 040_Speed already exists. Skipping...\n",
      "Processing:  041_Airline\n",
      "CSV for ID 041_Airline already exists. Skipping...\n",
      "Processing:  042_Predict\n",
      "CSV for ID 042_Predict already exists. Skipping...\n",
      "Processing:  043_Predict\n",
      "CSV for ID 043_Predict already exists. Skipping...\n",
      "Processing:  044_IMDb\n",
      "CSV for ID 044_IMDb already exists. Skipping...\n",
      "Processing:  045_Predict\n",
      "CSV for ID 045_Predict already exists. Skipping...\n",
      "Processing:  046_120\n",
      "CSV for ID 046_120 already exists. Skipping...\n",
      "Processing:  047_Bank\n",
      "CSV for ID 047_Bank already exists. Skipping...\n",
      "Processing:  048_Data\n",
      "CSV for ID 048_Data already exists. Skipping...\n",
      "Processing:  049_Boris\n",
      "CSV for ID 049_Boris already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "##### load in the forbes dataframe (pandas dataframes) #####\n",
    "\n",
    "\n",
    "qa_dict = {} # dict to store all qa \n",
    "output_folder = os.getcwd()\n",
    "for table in dfs_train:\n",
    "    print('Processing: ', table)\n",
    "    csv_file_path = os.path.join(output_folder, f\"{table}.csv\")\n",
    "    \n",
    "    # Load the qa.parquet dataframe and store it in the dictionary\n",
    "    qa = pd.read_parquet(f\"hf://datasets/cardiffnlp/databench/data/{table}/qa.parquet\")\n",
    "    qa_dict[table] = qa\n",
    "        \n",
    "    # Skip if the CSV file already exists\n",
    "    if os.path.exists(csv_file_path):\n",
    "        print(f\"CSV for ID {table} already exists. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Load the all.parquet dataframe and save it as CSV\n",
    "        df = pd.read_parquet(f\"hf://datasets/cardiffnlp/databench/data/{table}/sample.parquet\") # loading in the lite versions with only 20 rows\n",
    "        df.to_csv(csv_file_path, index=False)  #### RERUN THIS WHEN I DO THE REAL THING\n",
    "        print(f\"Saved CSV for ID {table} at {csv_file_path}.\")\n",
    "\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ID {table}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48667efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['001_Forbes', '002_Titanic', '003_Love', '004_Taxi', '005_NYC', '006_London', '007_Fifa', '008_Tornados', '009_Central', '010_ECommerce', '011_SF', '012_Heart', '013_Roller', '014_Airbnb', '015_Food', '016_Holiday', '017_Hacker', '018_Staff', '019_Aircraft', '020_Real', '021_Telco', '022_Airbnbs', '023_Climate', '024_Salary', '025_Data', '026_Predicting', '027_Supermarket', '028_Predict', '029_NYTimes', '030_Professionals', '031_Trustpilot', '032_Delicatessen', '033_Employee', '034_World', '035_Billboard', '036_US', '037_Ted', '038_Stroke', '039_Happy', '040_Speed', '041_Airline', '042_Predict', '043_Predict', '044_IMDb', '045_Predict', '046_120', '047_Bank', '048_Data', '049_Boris'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign all of the qa tables\n",
    "# for each need to manually assing the answer coordinate to each qa row\n",
    "qa_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77981439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only number and category answers for all qa dfs in qa_dict\n",
    "def extract_float(answer):\n",
    "    try:\n",
    "        return float(answer)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "for df in qa_dict:\n",
    "    qa = qa_dict[df] \n",
    "    qa = qa[qa['type'].isin(['number', 'category'])] # choose only the number and category answers\n",
    "    qa = qa.drop('answer', axis = 1) # drop the answer category for the not sample dataframe\n",
    "    qa = qa.loc[~qa['sample_answer'].isin(['0', 'None'])] # filter out answer of 0 or None\n",
    "    qa['dataset'] = qa['dataset'] + '.csv'\n",
    "    #print(qa.columns)\n",
    "    qa['float_answer'] = qa['sample_answer'].apply(extract_float)\n",
    "    qa_dict[df] = qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cdc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other questions to remove, make sure you only run this once\n",
    "qa_dict[dfs_train[0]] = qa_dict[dfs_train[0]].iloc[:-1]\n",
    "qa_dict[dfs_train[1]] = qa_dict[dfs_train[1]].reset_index(drop=True)\n",
    "qa_dict[dfs_train[1]] = qa_dict[dfs_train[1]].drop([2,3,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39d946af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many unique passenger classes are present in the dataset?\n",
      "     ---> 3\n",
      "\n",
      "\n",
      "What's the maximum age of the passengers?\n",
      "     ---> 69.0\n",
      "\n",
      "\n",
      "Which passenger class has the highest number of survivors?\n",
      "     ---> 3\n",
      "\n",
      "\n",
      "What's the most common gender among the survivors?\n",
      "     ---> female\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>type</th>\n",
       "      <th>columns_used</th>\n",
       "      <th>column_types</th>\n",
       "      <th>sample_answer</th>\n",
       "      <th>dataset</th>\n",
       "      <th>float_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many unique passenger classes are present ...</td>\n",
       "      <td>number</td>\n",
       "      <td>[Pclass]</td>\n",
       "      <td>['number[uint8]']</td>\n",
       "      <td>3</td>\n",
       "      <td>002_Titanic.csv</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the maximum age of the passengers?</td>\n",
       "      <td>number</td>\n",
       "      <td>[Age]</td>\n",
       "      <td>['number[UInt8]']</td>\n",
       "      <td>69.0</td>\n",
       "      <td>002_Titanic.csv</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which passenger class has the highest number o...</td>\n",
       "      <td>category</td>\n",
       "      <td>[Pclass, Survived]</td>\n",
       "      <td>['number[uint8]', 'boolean']</td>\n",
       "      <td>3</td>\n",
       "      <td>002_Titanic.csv</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What's the most common gender among the surviv...</td>\n",
       "      <td>category</td>\n",
       "      <td>[Sex, Survived]</td>\n",
       "      <td>['category', 'boolean']</td>\n",
       "      <td>female</td>\n",
       "      <td>002_Titanic.csv</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      type  \\\n",
       "0  How many unique passenger classes are present ...    number   \n",
       "1          What's the maximum age of the passengers?    number   \n",
       "4  Which passenger class has the highest number o...  category   \n",
       "5  What's the most common gender among the surviv...  category   \n",
       "\n",
       "         columns_used                  column_types sample_answer  \\\n",
       "0            [Pclass]             ['number[uint8]']             3   \n",
       "1               [Age]             ['number[UInt8]']          69.0   \n",
       "4  [Pclass, Survived]  ['number[uint8]', 'boolean']             3   \n",
       "5     [Sex, Survived]       ['category', 'boolean']        female   \n",
       "\n",
       "           dataset  float_answer  \n",
       "0  002_Titanic.csv           3.0  \n",
       "1  002_Titanic.csv          69.0  \n",
       "4  002_Titanic.csv           3.0  \n",
       "5  002_Titanic.csv           NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the qa (now on 002_Titanic)\n",
    "qa_id = dfs_train[1]\n",
    "qa = qa_dict[qa_id]\n",
    "for q, a in zip(qa['question'], qa['sample_answer']):\n",
    "    print(q)\n",
    "    print('     --->', a)\n",
    "    print('\\n')\n",
    "    \n",
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25933f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>type</th>\n",
       "      <th>columns_used</th>\n",
       "      <th>column_types</th>\n",
       "      <th>sample_answer</th>\n",
       "      <th>dataset</th>\n",
       "      <th>float_answer</th>\n",
       "      <th>answer_coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the age of the youngest billionaire?</td>\n",
       "      <td>number</td>\n",
       "      <td>['age']</td>\n",
       "      <td>['number[UInt8]']</td>\n",
       "      <td>32.0</td>\n",
       "      <td>001_Forbes.csv</td>\n",
       "      <td>32.0</td>\n",
       "      <td>[(11, 5)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What's the rank of the wealthiest non-self-mad...</td>\n",
       "      <td>number</td>\n",
       "      <td>['selfMade', 'rank']</td>\n",
       "      <td>['boolean', 'number[uint16]']</td>\n",
       "      <td>288</td>\n",
       "      <td>001_Forbes.csv</td>\n",
       "      <td>288.0</td>\n",
       "      <td>[(14, 6)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Which category does the richest billionaire be...</td>\n",
       "      <td>category</td>\n",
       "      <td>['finalWorth', 'category']</td>\n",
       "      <td>['number[uint32]', 'category']</td>\n",
       "      <td>Food &amp; Beverage</td>\n",
       "      <td>001_Forbes.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(7, 8)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What's the country of origin of the oldest bil...</td>\n",
       "      <td>category</td>\n",
       "      <td>['age', 'country']</td>\n",
       "      <td>['number[UInt8]', 'category']</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>001_Forbes.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(18, 10)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What's the gender of the billionaire with the ...</td>\n",
       "      <td>category</td>\n",
       "      <td>['philanthropyScore', 'gender']</td>\n",
       "      <td>['number[UInt8]', 'category']</td>\n",
       "      <td>M</td>\n",
       "      <td>001_Forbes.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(0, 4)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What's the source of wealth for the youngest b...</td>\n",
       "      <td>category</td>\n",
       "      <td>['age', 'source']</td>\n",
       "      <td>['number[UInt8]', 'category']</td>\n",
       "      <td>fintech</td>\n",
       "      <td>001_Forbes.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(11, 9)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question      type  \\\n",
       "5        What is the age of the youngest billionaire?    number   \n",
       "9   What's the rank of the wealthiest non-self-mad...    number   \n",
       "10  Which category does the richest billionaire be...  category   \n",
       "11  What's the country of origin of the oldest bil...  category   \n",
       "12  What's the gender of the billionaire with the ...  category   \n",
       "13  What's the source of wealth for the youngest b...  category   \n",
       "\n",
       "                       columns_used                    column_types  \\\n",
       "5                           ['age']               ['number[UInt8]']   \n",
       "9              ['selfMade', 'rank']   ['boolean', 'number[uint16]']   \n",
       "10       ['finalWorth', 'category']  ['number[uint32]', 'category']   \n",
       "11               ['age', 'country']   ['number[UInt8]', 'category']   \n",
       "12  ['philanthropyScore', 'gender']   ['number[UInt8]', 'category']   \n",
       "13                ['age', 'source']   ['number[UInt8]', 'category']   \n",
       "\n",
       "      sample_answer         dataset  float_answer answer_coords  \n",
       "5              32.0  001_Forbes.csv          32.0     [(11, 5)]  \n",
       "9               288  001_Forbes.csv         288.0     [(14, 6)]  \n",
       "10  Food & Beverage  001_Forbes.csv           NaN      [(7, 8)]  \n",
       "11   United Kingdom  001_Forbes.csv           NaN    [(18, 10)]  \n",
       "12                M  001_Forbes.csv           NaN      [(0, 4)]  \n",
       "13          fintech  001_Forbes.csv           NaN     [(11, 9)]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works for 001_Forbes \n",
    "qa_dict[dfs_train[0]]['answer_coords'] = [\n",
    "    [(11,5)], \n",
    "    [(14,6)],\n",
    "    [(7,8)],\n",
    "    [(18,10)],\n",
    "    [(0,4)],\n",
    "    [(11,9)] \n",
    "]\n",
    "\n",
    "# working on 002_Titanic\n",
    "qa_dict[dfs_train[1]]['answer_coords'] = [\n",
    "    [(0,4)], # this is a fudge\n",
    "    [(0,0)],\n",
    "    [(0,4)],\n",
    "    [(12,2)] \n",
    "]\n",
    "\n",
    "qa_dict[dfs_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3fdf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the forbes_001 working one as toy data set\n",
    "qa_dict[dfs_train[0]].to_csv('toy_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73bbba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# set up the WTQ style tokenizer\n",
    "config = TapasConfig.from_pretrained(\n",
    "    \"google/tapas-base-finetuned-wtq\",\n",
    "    aggregation_labels=True,  # Enable aggregation operators\n",
    ")\n",
    "\n",
    "# Initialize the tokenizer and model with the configuration\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
    "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14cbb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = 0 # 0 (001_Forbes works) and 1 (002_Titanic doesnt work)\n",
    "table = pd.read_csv(f'{dfs_train[df_num]}.csv').astype(str)\n",
    "queries = list(qa_dict[dfs_train[df_num]]['question'])\n",
    "answer_coordinates = list(qa_dict[dfs_train[df_num]]['answer_coords'])\n",
    "answer_text = list(qa_dict[dfs_train[df_num]]['sample_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0150d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:2673: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/opt/anaconda3/envs/cs375/lib/python3.11/site-packages/transformers/models/tapas/tokenization_tapas.py:1472: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'labels', 'numeric_values', 'numeric_values_scale', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    table = table,\n",
    "    queries = queries,\n",
    "    answer_coordinates = answer_coordinates,\n",
    "    answer_text = answer_text,\n",
    "    padding = \"max_length\",\n",
    "    truncation=True,  \n",
    "    return_tensors = \"pt\"\n",
    ")\n",
    "\n",
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea4a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
